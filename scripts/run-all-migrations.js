import postgres from 'postgres';
import * as dotenv from 'dotenv';
import { readFileSync, readdirSync } from 'fs';
import { join, dirname } from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

dotenv.config();

console.log('ğŸš€ Starting database migration...');

// ç¢ºä¿ DATABASE_URL å­˜åœ¨
if (!process.env.DATABASE_URL) {
  console.error('âŒ DATABASE_URL is not defined in environment variables');
  process.exit(1);
}

if (process.env.SKIP_DB_MIGRATION === 'true') {
  console.log('âš ï¸  SKIP_DB_MIGRATION=true, skipping migration.');
  process.exit(0);
}

const connectionString = process.env.DATABASE_URL;

async function runMigrations() {
  let client;
  
  try {
    // å»ºç«‹é€£æ¥
    try {
      client = postgres(connectionString, { connect_timeout: 10 });
    } catch (error) {
      console.warn(`âš ï¸  Invalid DATABASE_URL format. Skipping migration.`);
      console.log('â„¹ï¸  Hint: DATABASE_URL should be in format: postgresql://user:password@host:port/database');
      return;
    }
    
    try {
      await client`SELECT 1`;
    } catch (error) {
      const message = error?.message ?? '';
      const isNetworkError =
        message.includes('ENOTFOUND') ||
        message.includes('ECONNREFUSED') ||
        message.includes('ETIMEDOUT') ||
        message.includes('EHOSTUNREACH');
      if (isNetworkError && process.env.MIGRATION_STRICT !== 'true') {
        console.warn(
          `âš ï¸  Database not reachable (${message}). Skipping migration. ` +
            'Set MIGRATION_STRICT=true to fail on connection errors.'
        );
        return;
      }
      throw error;
    }
    
    console.log('âœ… Database connection established');
    
    // å»ºç«‹ migration è¿½è¹¤è¡¨
    await client`
      CREATE TABLE IF NOT EXISTS __drizzle_migrations (
        id SERIAL PRIMARY KEY,
        hash TEXT NOT NULL,
        created_at TIMESTAMP DEFAULT NOW()
      )
    `;
    console.log('âœ… Migration tracking table ready');
    
    // è®€å–æ‰€æœ‰ migration æª”æ¡ˆ
    const migrationsDir = join(__dirname, '../db/migrations');
    const files = readdirSync(migrationsDir)
      .filter(f => f.endsWith('.sql'))
      .sort(); // æŒ‰æª”åæ’åºï¼Œç¢ºä¿æŒ‰é †åºåŸ·è¡Œ
    
    console.log(`ğŸ“‚ Found ${files.length} migration files`);
    
    // å–å¾—å·²åŸ·è¡Œçš„ migrations
    const executedMigrations = await client`
      SELECT hash FROM __drizzle_migrations
    `;
    const executedHashes = new Set(executedMigrations.map(m => m.hash));
    
    console.log(`ğŸ“‹ Already executed: ${executedHashes.size} migrations`);
    
    // åŸ·è¡Œæ¯å€‹ migration æª”æ¡ˆ
    for (const file of files) {
      const hash = file; // ä½¿ç”¨æª”åä½œç‚º hash
      
      if (executedHashes.has(hash)) {
        console.log(`â­ï¸  Skipping ${file} (already executed)`);
        continue;
      }
      
      console.log(`ğŸ”„ Executing ${file}...`);
      
      const migrationPath = join(migrationsDir, file);
      const sql = readFileSync(migrationPath, 'utf-8');
      
      // åˆ†å‰² SQL èªå¥
      const statements = sql
        .split('--> statement-breakpoint')
        .map(s => s.trim())
        .filter(s => s.length > 0);
      
      console.log(`   Found ${statements.length} statements`);
      
      // åŸ·è¡Œæ¯å€‹ SQL èªå¥
      for (let i = 0; i < statements.length; i++) {
        const statement = statements[i];
        try {
          await client.unsafe(statement);
          console.log(`   âœ… Statement ${i + 1}/${statements.length} executed`);
        } catch (error) {
          // å¿½ç•¥å·²å­˜åœ¨çš„éŒ¯èª¤
          if (error.message.includes('already exists')) {
            console.log(`   âš ï¸  Statement ${i + 1}/${statements.length} skipped (already exists)`);
          } else {
            console.error(`   âŒ Statement ${i + 1}/${statements.length} failed:`, error.message);
            throw error;
          }
        }
      }
      
      // è¨˜éŒ„å·²åŸ·è¡Œçš„ migration
      await client`
        INSERT INTO __drizzle_migrations (hash) VALUES (${hash})
      `;
      
      console.log(`âœ… ${file} completed`);
    }
    
    console.log('âœ… All migrations completed successfully!');
    
    // é©—è­‰è³‡æ–™è¡¨
    const finalTables = await client`
      SELECT table_name 
      FROM information_schema.tables 
      WHERE table_schema = 'public'
      ORDER BY table_name
    `;
    
    console.log(`âœ… Database now has ${finalTables.length} tables`);
    console.log('ğŸ“‹ Tables:', finalTables.map(t => t.table_name).join(', '));
    
  } catch (error) {
    console.error('âŒ Migration failed:', error.message);
    console.log('âš ï¸  Migration failed but deployment will continue.');
    // Don't exit with error code to allow deployment to continue
  } finally {
    if (client) {
      await client.end();
      console.log('âœ… Database connection closed');
    }
  }
}

runMigrations();
